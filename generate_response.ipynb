{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper jupyter notebook file to generate more essays on the topic of electoral college. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating essay 1/51 at temperature 0.25...\n",
      "Generating essay 2/51 at temperature 0.26...\n",
      "Generating essay 3/51 at temperature 0.27...\n",
      "Generating essay 4/51 at temperature 0.28...\n",
      "Generating essay 5/51 at temperature 0.29...\n",
      "Generating essay 6/51 at temperature 0.3...\n",
      "Generating essay 7/51 at temperature 0.31...\n",
      "Generating essay 8/51 at temperature 0.32...\n",
      "Generating essay 9/51 at temperature 0.33...\n",
      "Generating essay 10/51 at temperature 0.33999999999999997...\n",
      "Generating essay 11/51 at temperature 0.35...\n",
      "Generating essay 12/51 at temperature 0.36...\n",
      "Generating essay 13/51 at temperature 0.37...\n",
      "Generating essay 14/51 at temperature 0.38...\n",
      "Generating essay 15/51 at temperature 0.39...\n",
      "Generating essay 16/51 at temperature 0.4...\n",
      "Generating essay 17/51 at temperature 0.41000000000000003...\n",
      "Generating essay 18/51 at temperature 0.42000000000000004...\n",
      "Generating essay 19/51 at temperature 0.43...\n",
      "Generating essay 20/51 at temperature 0.44...\n",
      "Generating essay 21/51 at temperature 0.45...\n",
      "Generating essay 22/51 at temperature 0.45999999999999996...\n",
      "Generating essay 23/51 at temperature 0.47...\n",
      "Generating essay 24/51 at temperature 0.48...\n",
      "Generating essay 25/51 at temperature 0.49...\n",
      "Generating essay 26/51 at temperature 0.5...\n",
      "Generating essay 27/51 at temperature 0.51...\n",
      "Generating essay 28/51 at temperature 0.52...\n",
      "Generating essay 29/51 at temperature 0.53...\n",
      "Generating essay 30/51 at temperature 0.54...\n",
      "Generating essay 31/51 at temperature 0.55...\n",
      "Generating essay 32/51 at temperature 0.56...\n",
      "Generating essay 33/51 at temperature 0.5700000000000001...\n",
      "Generating essay 34/51 at temperature 0.5800000000000001...\n",
      "Generating essay 35/51 at temperature 0.5900000000000001...\n",
      "Generating essay 36/51 at temperature 0.6000000000000001...\n",
      "Generating essay 37/51 at temperature 0.61...\n",
      "Generating essay 38/51 at temperature 0.62...\n",
      "Generating essay 39/51 at temperature 0.63...\n",
      "Generating essay 40/51 at temperature 0.64...\n",
      "Generating essay 41/51 at temperature 0.65...\n",
      "Generating essay 42/51 at temperature 0.66...\n",
      "Generating essay 43/51 at temperature 0.6699999999999999...\n",
      "Generating essay 44/51 at temperature 0.6799999999999999...\n",
      "Generating essay 45/51 at temperature 0.69...\n",
      "Generating essay 46/51 at temperature 0.7...\n",
      "Generating essay 47/51 at temperature 0.71...\n",
      "Generating essay 48/51 at temperature 0.72...\n",
      "Generating essay 49/51 at temperature 0.73...\n",
      "Generating essay 50/51 at temperature 0.74...\n",
      "Generating essay 51/51 at temperature 0.75...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_essays(prompt, filename, temperatures= np.linspace(0.25, 0.75, 51)):\n",
    "\n",
    "    for i, temp in enumerate(temperatures):\n",
    "        print(f\"Generating essay {i+1}/{len(temperatures)} at temperature {temp}...\")\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant writing an essay.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=float(temp)\n",
    "            )\n",
    "\n",
    "            # Extract the generated essay text\n",
    "            essay_text = response.choices[0].message.content\n",
    "            # Append the response to a JSON file\n",
    "            with open(filename, 'a') as file:\n",
    "                json.dump({\n",
    "                    'temperature': temp,\n",
    "                    'essay': essay_text,\n",
    "                    #'response_metadata': response\n",
    "                }, file)\n",
    "                file.write('\\n')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error at temperature {temp}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Example usage\n",
    "generate_essays(\"Write an essay on the topic: 'Does the electoral college work?'\", \"./data/elect_gpt4o_essays.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "essaydf = pd.read_json(\"./data/elect_gpt4o_essays.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "essaydf['word_count'] = essaydf['essay'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldf = pd.read_pickle(\"./data/elect_evaldf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'text_substring', 'text', 'label', 'prompt_name', 'source',\n",
       "       'RDizzl3_seven', 'model', 'embedding', 'text_embedded',\n",
       "       'text_embedding_tc', 'number_of_grammatical_errors',\n",
       "       'number_of_spelling_mistakes', 'grammatical_errors',\n",
       "       'spelling_mistakes', 'sentence_complexity', 'lexical_diversity',\n",
       "       'vocabulary_sophistication', 'coherence_score', 'cohesion_score',\n",
       "       'argument_structure', 'readability_index', 'sentence_clarity',\n",
       "       'engagement_score', 'sentiment_alignment', 'style_consistency',\n",
       "       'relevance_score', 'evidence_support', 'originality_and_creativity',\n",
       "       'likelihood_of_ai', 'reasoning_of_likelihood_of_ai',\n",
       "       'substrings_of_high_likelihood_of_ai', 'Author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaldf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "essaydf.rename(columns={'essay': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "esaydf['Author'] = 'AI'\n",
    "essaydf['source'] = 'GPT-4o'\n",
    "essaydf['model'] = 'gpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essaydf.to_pickle('./data/elect_gpt4o_essays.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

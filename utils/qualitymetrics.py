from pydantic import BaseModel, Field
from typing import Literal, List

class TextQualityMetrics(BaseModel):
    number_of_grammatical_errors: int = Field(..., description="Measures the frequency of grammar mistakes, such as incorrect verb tense, subject-verb disagreement, or improper sentence structure.")
    number_of_spelling_mistakes: int = Field(..., description="Counts the number of spelling mistakes found in the text.")

class QuantitativeTextQualityMetrics(TextQualityMetrics):
    grammatical_errors: List[str] = Field(..., description="Substrings of sentences or parts of text that contain grammatical errors, without modification, addition, or deletion.")
    spelling_mistakes: List[str] = Field(..., description="Substrings containing spelling mistakes, without modification, addition, or deletion.")

class EssayQualityMetrics(QuantitativeTextQualityMetrics):
    sentence_complexity: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Analyzes sentence structures, including average sentence length, use of compound or complex sentences, and syntactic variety.")
    lexical_diversity: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Assesses vocabulary richness, such as the comparison between the number of unique words vs the total word count.")
    vocabulary_sophistication: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Evaluates the use of advanced vocabulary by tracking less common or multi-syllabic words.")
    coherence_score: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Measures logical flow, often by evaluating transitions between paragraphs and the clarity of the argument.")
    cohesion_score: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Looks at how well sentences connect through linguistic devices such as conjunctions, pronouns, and other linking words.")
    argument_structure: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Analyzes the logical flow of arguments, checking for clear topic sentences, supporting evidence, and conclusions.")
    readability_index: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Measures readability levels indicating how easy the text is to understand.")
    sentence_clarity: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Evaluates sentence construction for ambiguity, clarity, and conciseness.")
    engagement_score: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Analyzes engagement by looking at rhetorical questions, examples, and variation in sentence structure.")
    sentiment_alignment: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Determines the tone or sentiment of the writing, assessing if it aligns with the intended emotion or argument strength.")
    style_consistency: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Examines consistency in tone, formality, and voice throughout the piece.")
    relevance_score: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Assesses if the content aligns with the prompt or main question being addressed.")
    evidence_support: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Measures the presence and quality of evidence provided to back up claims, such as statistics, quotes, or examples.")
    originality_and_creativity: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Evaluates the uniqueness of ideas, focusing on originality in approach, insight, or perspective.")

class EssayQualityMetricsWithAI(EssayQualityMetrics):
    likelihood_of_ai: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Predicts the likelihood of the essay being written by an AI model based on various linguistic features, where 0 is least likely and 5 is most likely to be written by AI.") 
    reasoning_of_likelihood_of_ai: str = Field(..., description="Provides a rationale for the predicted likelihood of the essay being generated by an AI model.")   
    substrings_of_high_likelihood_of_ai: List[str] = Field(..., description="Specific phrases or sentences that contribute to the high likelihood of the essay being generated by an AI model, without modification, addition, or deletion.") 

class AIQualityMetrics(BaseModel):
    likelihood_of_ai: Literal[0, 1, 2, 3, 4, 5] = Field(..., description="Predicts the likelihood of the essay being written by an AI model based on various linguistic features, where 0 is least likely and 5 is most likely to be written by AI.") 
    reasoning_of_likelihood_of_ai: str = Field(..., description="Provides a rationale for the predicted likelihood of the essay being generated by an AI model.")   
    substrings_of_high_likelihood_of_ai: List[str] = Field(..., description="Specific phrases or sentences that contribute to the high likelihood of the essay being generated by an AI model, without modification, addition, or deletion.") 
